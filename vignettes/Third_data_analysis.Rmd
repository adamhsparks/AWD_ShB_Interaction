---
title: "Sheath Blight Analysis"
author: "Adam H Sparks"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    theme: yeti
vignette: >
  %\VignetteIndexEntry{03_Sheath_Blight_Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

Based on the residual plots where several do not meet assumptions for a normal distribution, I've elected to use `MCMCglmm()` for a split plot analysis rather than a `lmer()` model. The `MCMCglmm()` model will work for all the data regardless of the residuals.

#### Interpreting These Analyses

The _MCMCglmm_ documentation provides an excellent resource for interpreting the outputs for each of the models below.

```{r MCMCglmm, eval=FALSE}
library(MCMCglmm)
vignette("Overview")
vignette("CourseNotes")
```

When comparing the treatments in the analysis, the model compares each treatment to the base (control) treatment.

The base levels for this analysis are:

- 2015 
  
    - `NRTE:0`

    - `WMGT:FLD`

- 2016

    - `NRTE:60`

    - `WMGT:FLD`

#### Changes between 2015 and 2016

Before the analysis, note that due to changes between the years, the analysis
must be carried out on each year separately. The 2015 data and 2016 data cannot
be combined due to changes in inoculation methods; there are other changes too,
but the main one is this. Therefore, the analyses will be conducted separately
such that comparisons will only be observational and cannot be statistically
compared.

#### _MCMCglmm_ Model Fitting Notes

Fitting the models with the default iterations resulted in some less than
acceptable models. Because of this, the number of iterations has been increased,
`nitt = 55000,` and `burnin = 5000` and `thin = 10`. This results in a sample
size of 5000 and much smaller errors for random effects and better models.

## Setup

Use `set.seed()` for reproducibility.

```{r set_seed, message=FALSE}
library(coda)
library(dplyr)
library(rice.awd.pests)
library(reshape2)
library(magrittr)
library(MCMCglmm)
library(foreach)
library(doParallel)
library(parallel)
library(plotMCMC)
library(tidyr)

set.seed(27)
```

The `AUDPS` object is loaded with the `rice.awd.pests` R package. To see how the AUDPC data were generated from the original raw data, see the [https://github.com/openplantpathology/rice_awd_pests/blob/master/data-raw](https://github.com/openplantpathology/rice_awd_pests/blob/master/data-raw) file. However, because it is a `tibble()` and the treatments exist in a single column for graphing the raw data, this object needs a few minor changes to be usable for the analysis.

Create individual data frames for the analysis.

```{r create_analysis_df, cache=FALSE, message=FALSE}
# create 2015 data frame
AUDPS_2015 <- as.data.frame(AUDPS[AUDPS$YEAR == 2015, ])
AUDPS_2015 <- droplevels(AUDPS_2015)

# relevel factors for easier interpretation of  analysis
AUDPS_2015 <- within(AUDPS_2015, NRTE <- relevel(NRTE, ref = "N0"))
AUDPS_2015 <- within(AUDPS_2015, WMGT <- relevel(WMGT, ref = "FLD"))

# create 2016 data frame
AUDPS_2016 <- as.data.frame(AUDPS[AUDPS$YEAR == 2016, ])
AUDPS_2016 <- droplevels(AUDPS_2016)

# relevel factors for easier interpretation of  analysis
AUDPS_2016 <- within(AUDPS_2016, NRTE <- relevel(NRTE, ref = "N60"))
AUDPS_2016 <- within(AUDPS_2016, WMGT <- relevel(WMGT, ref = "FLD"))
```

Now that the `AUDPS_2015` and `AUDPS_2016` `data.frames()` exist, we can start
the analysis.

## Check Correlation

Check for correlation between the tiller incidence and the severity ratings for both leaf and tiller.

```{r correlation}
# 2015 Tiller Severity Correlation
cor.test(AUDPS_2015$TShB_inc_AUDPS,
         AUDPS_2015$TShB_sev_AUDPS,
         method = "spearman",
         alternative = "two.sided",
         exact = FALSE)

# 2015 Leaf Severity Correlation
cor.test(AUDPS_2015$TShB_inc_AUDPS,
         AUDPS_2015$LShB_sev_AUDPS,
         method = "spearman",
         alternative = "two.sided",
         exact = FALSE)

# 2016 Tiller Severity Correlation
cor.test(AUDPS_2016$TShB_inc_AUDPS,
         AUDPS_2016$TShB_sev_AUDPS,
         method = "spearman",
         alternative = "two.sided",
         exact = FALSE)

# 2016 Leaf Severity Correlation
cor.test(AUDPS_2016$TShB_inc_AUDPS,
         AUDPS_2016$LShB_sev_AUDPS,
         method = "spearman",
         alternative = "two.sided",
         exact = FALSE)
```

The tiller incidence of the disease appears not to be correlated with the severity on the tiller or the leaves. Based on this, the interactions of the incidence and severity will not be analysed.

## Specify Priors

As `MCMCglmm` is a Bayesian analysis, it requires priors to be set. Here we set
flat noninformative priors that have a uniform low degree of belief in all
parameters for all six models we will create.

```{r priors}
eprior <- list(R = list(V = 1, nu = 0.002),
               G = list(G1 = list( V = 1, n = 1, alpha.mu = 0, alpha.V = 25^2)))
```

## 2015 Models

### 2015 Tiller Sheath Blight Incidence Model

```{r 2015_TShB_incidence, cache=FALSE}
cl <- makePSOCKcluster(detectCores())
registerDoParallel(cl)

m1 <- foreach(1:4, .packages = "MCMCglmm") %dopar% {
  MCMCglmm(TShB_inc_AUDPS ~ WMGT + NRTE,
           random = ~REP, 
           data = AUDPS_2015,
           verbose = FALSE,
           prior = eprior,
           nitt = 55000,
           burnin = 5000,
           thin = 10)
}

stopCluster(cl)

m1 <- lapply(m1, function(m) m$Sol)
m1 <- do.call(mcmc.list, m1)

summary(m1)

par(mfrow = c(4, 1), mar = c(2, 2, 1, 2))
gelman.plot(m1, auto.layout = FALSE)

gelman.diag(m1)

par(mfrow = c(4, 2), mar = c(2, 1, 1, 1))
plot(m1, ask = FALSE, auto.layout = FALSE)

plot_estimates(m1)

```

### 2015 Tiller Sheath Blight Severity Model

```{r 2015_TShB_severity, cache=FALSE}
cl <- makePSOCKcluster(detectCores())
registerDoParallel(cl)

m2 <- foreach(1:4, .packages = "MCMCglmm") %dopar% {
  MCMCglmm(TShB_percent_AUDPS ~ WMGT + NRTE,
           random = ~REP, 
           data = AUDPS_2015,
           verbose = FALSE,
           prior = eprior,
           nitt = 55000,
           burnin = 5000,
           thin = 10)
}

stopCluster(cl)

m2 <- lapply(m2, function(m) m$Sol)
m2 <- do.call(mcmc.list, m2)

summary(m2)

par(mfrow = c(4, 1), mar = c(2, 2, 1, 2))
gelman.plot(m2, auto.layout = FALSE)

gelman.diag(m2)

par(mfrow = c(4, 2), mar = c(2, 1, 1, 1))
plot(m2, ask = FALSE, auto.layout = FALSE)

plot_estimates(m2)
```

### 2015 Leaf Sheath Blight Severity Model

```{r 2015_LShB_severity, cache=FALSE}
cl <- makePSOCKcluster(detectCores())
registerDoParallel(cl)

m3 <- foreach(1:4, .packages = "MCMCglmm") %dopar% {
  MCMCglmm(LShB_percent_AUDPS ~ WMGT + NRTE,
           random = ~REP, 
           data = AUDPS_2015,
           verbose = FALSE,
           prior = eprior,
           nitt = 55000,
           burnin = 5000,
           thin = 10)
}

stopCluster(cl)

m3 <- lapply(m3, function(m) m$Sol)
m3 <- do.call(mcmc.list, m3)

summary(m3)

par(mfrow = c(4, 1), mar = c(2, 2, 1, 2))
gelman.plot(m3, auto.layout = FALSE)

gelman.diag(m3)

par(mfrow = c(4, 2), mar = c(2, 1, 1, 1))
plot(m3, ask = FALSE, auto.layout = FALSE)

plot_estimates(m3)
```

*******

## 2016 Models

### 2016 Tiller Sheath Blight Incidence Model

```{r 2016_TShB_incidence, cache=FALSE}
cl <- makePSOCKcluster(detectCores())
registerDoParallel(cl)

m4 <- foreach(1:4, .packages = "MCMCglmm") %dopar% {
  MCMCglmm(TShB_inc_AUDPS ~ WMGT + NRTE,
           random = ~REP, 
           data = AUDPS_2016,
           verbose = FALSE,
           prior = eprior,
           nitt = 55000,
           burnin = 5000,
           thin = 10)
}

stopCluster(cl)

m4 <- lapply(m4, function(m) m$Sol)
m4 <- do.call(mcmc.list, m4)

summary(m4)

par(mfrow = c(3, 1), mar = c(2, 2, 1, 2))
gelman.plot(m4, auto.layout = FALSE)

gelman.diag(m4)

par(mfrow = c(3, 2), mar = c(2, 1, 1, 1))
plot(m4, ask = FALSE, auto.layout = FALSE)

plot_estimates(m4)
```


### 2016 Tiller Sheath Blight Severity Model

```{r 2016_TShB_severity, cache=FALSE}
cl <- makePSOCKcluster(detectCores())
registerDoParallel(cl)

m5 <- foreach(1:4, .packages = "MCMCglmm") %dopar% {
  MCMCglmm(TShB_percent_AUDPS ~ WMGT + NRTE,
           random = ~REP, 
           data = AUDPS_2016,
           verbose = FALSE,
           prior = eprior,
           nitt = 55000,
           burnin = 5000,
           thin = 10)
}

stopCluster(cl)

m5 <- lapply(m5, function(m) m$Sol)
m5 <- do.call(mcmc.list, m5)

summary(m5)

par(mfrow = c(3, 1), mar = c(2, 2, 1, 2))
gelman.plot(m5, auto.layout = FALSE)

gelman.diag(m5)

par(mfrow = c(3, 2), mar = c(2, 1, 1, 1))
plot(m5, ask = FALSE, auto.layout = FALSE)

plot_estimates(m5)
```

### 2016 Leaf Sheath Blight Severity Model

```{r 2016_LShB_severity, cache=FALSE}
cl <- makePSOCKcluster(detectCores())
registerDoParallel(cl)

m6 <- foreach(1:4, .packages = "MCMCglmm") %dopar% {
  MCMCglmm(LShB_percent_AUDPS ~ WMGT + NRTE,
           random = ~REP, 
           data = AUDPS_2016,
           verbose = FALSE,
           prior = eprior,
           nitt = 55000,
           burnin = 5000,
           thin = 10)
}

stopCluster(cl)

m6 <- lapply(m6, function(m) m$Sol)
m6 <- do.call(mcmc.list, m6)

summary(m6)

par(mfrow = c(3, 1), mar = c(2, 2, 1, 2))
gelman.plot(m6, auto.layout = FALSE)

gelman.diag(m6)

par(mfrow = c(3, 2), mar = c(2, 1, 1, 1))
plot(m6, ask = FALSE, auto.layout = FALSE)

plot_estimates(m6)
```

### Model Fit

The models all appear to be good fits.

None of the diagnostic plots show any signs of auto-correlation or any other obvious patterns that would indicate issues with the models.

The random effects all appear to be acceptable, the dotted line stays near to the solid line with no discernible patterns.

## Conclusions

### Tiller Sheath Blight Incidence

In 2015 both the nitrogen rates, N100 and N120, were significant when compared with the base N0 rate, water management was not significantly different.

In 2016 the nitrogen rate N180, was significantly different than the base N60 rate, water management was not significantly different.

### Tiller Sheath Blight Severity

In 2015 both the N100 and N120 rates were significantly different than the N0 treatment. The AWD water management was not significantly different from the base FLD treatment.

In 2016 the N180 was significantly different from the N60 rate. The AWD water management was also significantly different from the base FLD treatment.

### Leaf Sheath Blight Severity

In 2015 both the N100 and N120 rates were significantly different than the N0 treatment. The AWD water management was not significantly different from the control FLD treatment.

In 2016 the neither of the treatments, nitrogen rate or water management, were significantly different from the base treatments for leaf sheath blight severity.

# Save Model Information

Lastly, save the model information used in the posterior estimate graphs to be used in the paper.

```{r save_models}

models <- list("TInc_15" = m1,
               "TSev_15" = m2,
               "LSev_15" = m3,
               "TInc_16" = m4,
               "TSev_16" = m5,
               "LSev_16" = m6)
saveRDS(models, "../analysis/data/derived_data/models.Rds")

```
